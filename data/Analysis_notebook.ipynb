{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "from preprolib import myfunctions\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the data\n",
    "df = pd.read_csv(r'C:\\Users\\User\\Desktop\\Projects\\Green Crop Yield\\data\\Train.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\User\\Desktop\\Projects\\Green Crop Yield\\data\\Test.csv')\n",
    "data_desc = pd.read_csv(r'C:\\Users\\User\\Desktop\\Projects\\Green Crop Yield\\data\\VariableDescription.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Example: Data Preprocessing\n",
    "cat_cols = []\n",
    "num_cols = []\n",
    "ignore_list = ['ID','CropTillageDate', 'RcNursEstDate','Yield','SeedingSowingTransplanting','Harv_date','Threshing_date']\n",
    "\n",
    "myfunctions.cat_or_num(df, ignore_list, num_cols, cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame named 'df'\n",
    "# 'cat_cols' is a list of categorical column names\n",
    "\n",
    "# Create a list to store column names that meet the criteria\n",
    "filtered_cat_cols = []\n",
    "\n",
    "# Iterate through the categorical columns\n",
    "for col in cat_cols:\n",
    "    unique_values = df[col].nunique()  # Count the unique values in the column\n",
    "    if unique_values <= 5:  # Check if there are 5 or fewer unique values\n",
    "        filtered_cat_cols.append(col)\n",
    "\n",
    "# Create a new DataFrame with the selected columns\n",
    "filtered_cat_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'Yield'\n",
    "features = num_cols + filtered_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_plots = len(features)\n",
    "fig, axes = plt.subplots(num_plots, 1, figsize=(10, 5*num_plots))\n",
    "\n",
    "# Loop through the features list and plot histograms\n",
    "for i, col in enumerate(cat_cols):\n",
    "    ax = axes[i]\n",
    "    if col in num_cols:\n",
    "        # If it's a numerical column, plot a histogram\n",
    "        sns.histplot(data=df, x=col, ax=ax, kde=True)\n",
    "        ax.set_title(f'Histogram of {col} (Numerical)')\n",
    "    else:\n",
    "        # If it's a categorical column, plot a countplot\n",
    "        sns.countplot(data=df, x=col, ax=ax)\n",
    "        ax.set_title(f'Countplot of {col} (Categorical)')\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "# Adjust layout and show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "sep_cols = ['CropbasalFerts', 'OrgFertilizers', 'TransDetFactor', 'NursDetFactor', 'LandPreparationMethod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have your DataFrame named 'data'\n",
    "# Initialize a list to store columns with more than 1000 null values\n",
    "columns_with_more_than_1000_nulls = []\n",
    "\n",
    "for column in df[num_cols].columns:\n",
    "    null_count = df[column].isnull().sum()\n",
    "    if null_count > 1000:\n",
    "        columns_with_more_than_1000_nulls.append(column)    \n",
    "\n",
    "columns_with_more_than_1000_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,sep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def onehot_seperator(df, columns):\n",
    "    unique_words = set()  # Initialize an empty set to store unique words\n",
    "    \n",
    "    for column in columns:\n",
    "        # Split the column values into words\n",
    "        df[column] = df[column].astype(str)\n",
    "        words = df[column].str.split()\n",
    "\n",
    "        # Create a set of unique words for this column, excluding NaN\n",
    "        unique_words.update(word for word_list in words if word_list is not None for word in word_list)\n",
    "\n",
    "    return unique_words\n",
    "\n",
    "unique_words = onehot_seperator(df, sep_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def onehot_seperator(df, columns, test=None):\n",
    "    for column in columns:\n",
    "        # Check if the column contains non-null string values\n",
    "        if df[column].dtype == 'object':\n",
    "            # Split the column values into words\n",
    "            df[column] = df[column].astype(str)\n",
    "            words = df[column].str.split()\n",
    "\n",
    "            # Create a set of unique words\n",
    "            unique_words = set(word for word_list in words for word in word_list)\n",
    "\n",
    "            # Create binary columns for each unique word in the original dataframe\n",
    "            for word in unique_words:\n",
    "                df[word] = df[column].apply(lambda x: word in x)\n",
    "                df[word] = df[word].replace({True: 1, False: 0})\n",
    "\n",
    "            # If a test dataframe is provided, create the same columns in the test dataframe\n",
    "            if test is not None:\n",
    "                for word in unique_words:\n",
    "                    if test[column].dtype == 'object':\n",
    "                        test[column] = test[column].astype(str)\n",
    "                        test[word] = test[column].apply(lambda x: word in x)\n",
    "                        test[word] = test[word].astype(int)\n",
    "\n",
    "    return df, test\n",
    "\n",
    "df, test = onehot_seperator(df, sep_cols, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with more than 1000 null values from 'num_cols'\n",
    "num_cols = [col for col in num_cols if col not in columns_with_more_than_1000_nulls]\n",
    "\n",
    "#TODO : Conduct PCA, Mutual information analysis and categorical separation for feature selection.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.extend(unique_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load your dataset into a DataFrame df\n",
    "\n",
    "# Define the columns for PCA\n",
    "pca_columns = num_cols\n",
    "\n",
    "\n",
    "# Create transformers for PCA columns\n",
    "pca_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=10))  # You can adjust the number of components\n",
    "])\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Custom transformer using onehot_seperator\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))])\n",
    "\n",
    "# Create a column transformer that applies the transformers to the respective columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('pca', pca_transformer, pca_columns),\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, filtered_cat_cols)\n",
    "    ])\n",
    "\n",
    "# Create the full data preprocessing pipeline\n",
    "data_preprocessing_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# Fit and transform the data\n",
    "X = df[features]\n",
    "y = df[label]\n",
    "X_preprocessed = data_preprocessing_pipeline.fit_transform(X)\n",
    "\n",
    "test_filtered = test[features]\n",
    "test_preprocessed = data_preprocessing_pipeline.fit_transform(test_filtered)\n",
    "\n",
    "# Scale the target variable y\n",
    "y_scaler = StandardScaler()\n",
    "y_scaled = y_scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now you have X_train, X_test, y_train, and y_test for further processing with selected features\n",
    "\n",
    "# Display a sample of the preprocessed data\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'SVR': SVR(),\n",
    "    'K-Nearest Neighbors': KNeighborsRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Elastic Net': ElasticNet(),\n",
    "    'Bayesian Ridge': BayesianRidge(),\n",
    "    'Neural Network': MLPRegressor(),\n",
    "    'Gaussian Process': GaussianProcessRegressor(),\n",
    "    'XGBoost': XGBRegressor(),\n",
    "    'LightGBM': LGBMRegressor(),\n",
    "    'CatBoost': CatBoostRegressor(learning_rate=0.1),  # Adjust hyperparameters as needed\n",
    "\n",
    "}\n",
    "\n",
    "# Create a dictionary to store RMSE values\n",
    "rmse_results = {}\n",
    "\n",
    "# Iterate through the models and calculate RMSE\n",
    "for model_name, model in models.items():\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # Store the RMSE in the dictionary\n",
    "    rmse_results[model_name] = rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4728\\3930545847.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_scores = model_scores.append({'Model': model_name, 'RMSE': rmse}, ignore_index=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4728\\3930545847.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_scores = model_scores.append({'Model': model_name, 'RMSE': rmse}, ignore_index=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4728\\3930545847.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_scores = model_scores.append({'Model': model_name, 'RMSE': rmse}, ignore_index=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4728\\3930545847.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_scores = model_scores.append({'Model': model_name, 'RMSE': rmse}, ignore_index=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4728\\3930545847.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_scores = model_scores.append({'Model': model_name, 'RMSE': rmse}, ignore_index=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4728\\3930545847.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_scores = model_scores.append({'Model': model_name, 'RMSE': rmse}, ignore_index=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4728\\3930545847.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_scores = model_scores.append({'Model': model_name, 'RMSE': rmse}, ignore_index=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4728\\3930545847.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_scores = model_scores.append({'Model': model_name, 'RMSE': rmse}, ignore_index=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4728\\3930545847.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_scores = model_scores.append({'Model': model_name, 'RMSE': rmse}, ignore_index=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4728\\3930545847.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_scores = model_scores.append({'Model': model_name, 'RMSE': rmse}, ignore_index=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4728\\3930545847.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_scores = model_scores.append({'Model': model_name, 'RMSE': rmse}, ignore_index=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4728\\3930545847.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_scores = model_scores.append({'Model': model_name, 'RMSE': rmse}, ignore_index=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4728\\3930545847.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_scores = model_scores.append({'Model': model_name, 'RMSE': rmse}, ignore_index=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4728\\3930545847.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_scores = model_scores.append({'Model': model_name, 'RMSE': rmse}, ignore_index=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4728\\3930545847.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_scores = model_scores.append({'Model': model_name, 'RMSE': rmse}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Print the RMSE for each model\n",
    "model_scores = pd.DataFrame() \n",
    "for model_name, rmse in rmse_results.items():\n",
    "    model_scores = model_scores.append({'Model': model_name, 'RMSE': rmse}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>779.545978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>784.963579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>788.486339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>791.293981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>794.026764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>804.550047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>804.728970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>805.346067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bayesian Ridge</td>\n",
       "      <td>805.695015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>810.093015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>815.839712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>831.731213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>846.533437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>942.095175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gaussian Process</td>\n",
       "      <td>1203.735035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model         RMSE\n",
       "5     Gradient Boosting   779.545978\n",
       "1         Random Forest   784.963579\n",
       "13             LightGBM   788.486339\n",
       "14             CatBoost   791.293981\n",
       "12              XGBoost   794.026764\n",
       "0     Linear Regression   804.550047\n",
       "6      Ridge Regression   804.728970\n",
       "7      Lasso Regression   805.346067\n",
       "9        Bayesian Ridge   805.695015\n",
       "10       Neural Network   810.093015\n",
       "4   K-Nearest Neighbors   815.839712\n",
       "8           Elastic Net   831.731213\n",
       "2         Decision Tree   846.533437\n",
       "3                   SVR   942.095175\n",
       "11     Gaussian Process  1203.735035"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores_sorted = model_scores.sort_values(by='RMSE', ascending=True)\n",
    "model_scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = GradientBoostingRegressor(random_state=1).fit(X_train, y_train)  # Convert one-hot encoded y_train to 1D array\n",
    "gb_predictions = gb_model.predict(test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([574.19673864, 390.71315085, 513.68163805, ..., 241.51720092,\n",
       "       387.43861496, 316.7051958 ])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(random_state=1).fit(X_train, y_train)  # Convert one-hot encoded y_train to 1D array\n",
    "rf_predictions = rf_model.predict(test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model = CatBoostRegressor(learning_rate=0.1, random_state=1).fit(X_train, y_train)  # Convert one-hot encoded y_train to 1D array\n",
    "cb_predictions = cb_model.predict(test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Yield'] = gb_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_cols = ['ID', 'Yield']\n",
    "Submission = test[sub_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission.to_csv('Submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NewEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
